[Dims]
latent_dim = 128
hidden_dim_0 = 1024
hidden_dim_1 = 512

[Hyperparameters]
lr = 0.001
num_epochs = 90
beta = 0.001
seed = 69

[Model]
batch_size = 128

[Agent]
training_model = VAE
save_model = 0
mask_ratio = 0.75

[Data]
metric = ax
test_size = 0.2
test_mode = 0

[callbacks]
neptune_project = mitrengamark/Autoencoder-Identification
neptune_token = "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NWJiMzAyNC02MWE2LTRhZDItYTgxNi0wZjg2ZjFjNTg5NTEifQ=="